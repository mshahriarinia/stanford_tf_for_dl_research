{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Character-level generative language model, based on Andrej Karpathy's blog: \n",
    "http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n",
    "\n",
    "We’ll train RNN character-level language models. That is, we’ll give the RNN a huge chunk of text \n",
    "and ask it to model the probability distribution of the next character in the sequence given a \n",
    "sequence of previous characters. This will then allow us to generate new text one character at a time.\n",
    "\n",
    "Note: Minimal character-level language model with a Vanilla Recurrent Neural Network, in Python/numpy\n",
    "https://gist.github.com/karpathy/d4dee566867f8291f086\n",
    "\n",
    "Note: Temperature: We can also play with the temperature of the Softmax during sampling. Decreasing \n",
    "the temperature from 1 to some lower number (e.g. 0.5) makes the RNN more confident, but also more\n",
    "conservative in its samples. Conversely, higher temperatures will give more diversity but at cost of \n",
    "more mistakes (e.g. spelling mistakes, etc). In particular, setting temperature very near zero will \n",
    "give the most likely thing that Paul Graham might say:\n",
    "\n",
    "“is that they were all the same thing that was a startup is that they were all the same thing that \n",
    "was a startup is that they were all the same thing that was a startup is that they were all the same”\n",
    "\n",
    "looks like we’ve reached an infinite loop about startups.\n",
    "\n",
    "Note: Generated baby names could be a quite useful inspiration when writing a novel, or naming a new startup :)\n",
    "http://cs.stanford.edu/people/karpathy/namesGenUnique.txt\n",
    "\"\"\"\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "DATA_PATH = 'data/arvix_abstracts.txt'\n",
    "HIDDEN_SIZE = 200\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "MAX_SEQ_WINDOW_SIZE = 50\n",
    "WINDOWING_STEP = MAX_SEQ_WINDOW_SIZE//2\n",
    "\n",
    "SKIP_STEP = 40\n",
    "TEMPRATURE = 0.7\n",
    "LR = 0.003\n",
    "LEN_GENERATED = 300\n",
    "vocab = (\" $%'()+,-./0123456789:;=?ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "            \"\\\\^_abcdefghijklmnopqrstuvwxyz{|}\")\n",
    "\n",
    "def make_dir(path):\n",
    "    \"\"\" Create a directory if there isn't one already. \"\"\"\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "    except OSError:\n",
    "        pass\n",
    "\n",
    "# Convert each char to its location in vocab\n",
    "def vocab_encode(text, vocab):\n",
    "    return [vocab.index(x) + 1 for x in text if x in vocab]\n",
    "\n",
    "# For each number in array return its equivalent char in vocab\n",
    "def vocab_decode(array, vocab):\n",
    "    return ''.join([vocab[x - 1] for x in array])\n",
    "\n",
    "def read_data(filename, vocab, max_seq_window_size=MAX_SEQ_WINDOW_SIZE, windowing_step=WINDOWING_STEP):\n",
    "    \"\"\" \n",
    "    1. Read the data line by line, \n",
    "    2. Encode chars based on their vocab index\n",
    "    3. Split long sequences to MAX_SEQ_WINDOW_SIZE pieces with a WINDOWING_STEP to move forward\n",
    "    \"\"\"\n",
    "    for text in open(filename):\n",
    "        text = vocab_encode(text, vocab)\n",
    "        for start in range(0, len(text) - max_seq_window_size, windowing_step):\n",
    "            chunk = text[start: start + max_seq_window_size]\n",
    "            #chunk += [0] * (max_seq_window_size - len(chunk))\n",
    "            yield chunk\n",
    "\n",
    "def read_batch(stream, batch_size=BATCH_SIZE):\n",
    "    \"\"\"\n",
    "    Combine input samples together to form batch_size array\n",
    "    \"\"\"\n",
    "    batch = []\n",
    "    for element in stream:\n",
    "        batch.append(element)\n",
    "        if len(batch) == batch_size:\n",
    "            yield batch\n",
    "            batch = []\n",
    "    yield batch    \n",
    "\n",
    "    \n",
    "######################  CREATE MODEL\n",
    "seq = tf.placeholder(tf.int32, [None, None])\n",
    "seq_one_hot = tf.one_hot(indices=seq, depth=len(vocab)) # indexes are converted to one-hot\n",
    "temperature = tf.placeholder(tf.float32)\n",
    "\n",
    "# Initialize RNN parameters\n",
    "cell_type = tf.contrib.rnn.GRUCell(HIDDEN_SIZE)\n",
    "initial_state = tf.placeholder_with_default(cell_type.zero_state(tf.shape(seq_one_hot)[0], tf.float32), [None, HIDDEN_SIZE])\n",
    "length = tf.reduce_sum(tf.reduce_max(tf.sign(seq_one_hot), 2), 1)\n",
    "\n",
    "output, out_state = tf.nn.dynamic_rnn(cell=cell_type, inputs=seq_one_hot, sequence_length=length, initial_state=initial_state)\n",
    "\n",
    "# fully_connected is syntactic sugar for tf.matmul(w, output) + b it will create w and b for us\n",
    "logits = tf.contrib.layers.fully_connected(output, len(vocab), None)\n",
    "loss = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(logits=logits[:, :-1], labels=seq_one_hot[:, 1:]))\n",
    "\n",
    "# Generate ONE sample from a multinomial distrbution (a binomial distribution with k options instead of 2). \n",
    "# We have at each slice [i, :] the unnormalized log-probabilities for all classes. adjusted with \n",
    "# temperature, as the next character\n",
    "# The higher the temprature divident, the more emphasis is going to be on the large value, the lower it is \n",
    "# other probabilitied options have more chance to live at an EXPONENTIAL level\n",
    "sample = tf.multinomial(tf.exp(logits[:, -1] / temperature), 1)[:, 0] \n",
    "\n",
    "###################\n",
    "\n",
    "global_step = tf.Variable(0, dtype=tf.int32, trainable=False, name='global_step')\n",
    "optimizer = tf.train.AdamOptimizer(LR).minimize(loss, global_step=global_step)\n",
    "make_dir('checkpoints')\n",
    "make_dir('checkpoints/arvix')\n",
    "\n",
    "# train\n",
    "saver = tf.train.Saver()\n",
    "start = time.time()\n",
    "with tf.Session() as sess:\n",
    "    writer = tf.summary.FileWriter('graphs/gist', sess.graph)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    ckpt = tf.train.get_checkpoint_state(os.path.dirname('checkpoints/arvix/checkpoint'))\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "\n",
    "    iteration = global_step.eval()\n",
    "    for batch in read_batch(read_data(DATA_PATH, vocab)):\n",
    "        batch_loss, _ = sess.run([loss, optimizer], {seq: batch})    # train\n",
    "        if (iteration + 1) % SKIP_STEP == 0:\n",
    "            print('Iter {}. \\n    Loss {}. Time {}'.format(iteration, batch_loss, time.time() - start))\n",
    "            #inference(sess, vocab, seq, sample, temperature, initial_state, out_state) \n",
    "            #####\n",
    "            \"\"\" \n",
    "            Generate sequence one character at a time, based on the previous character\n",
    "            \"\"\"\n",
    "            sentence = 'T'\n",
    "            state = None\n",
    "            for _ in range(LEN_GENERATED):\n",
    "                batch = [vocab_encode(sentence[-1], vocab)]\n",
    "                feed = {seq: batch, temperature: TEMPRATURE}\n",
    "                # for the first decoder step, the state is None\n",
    "                if state is not None:\n",
    "                    feed.update({initial_state: state})\n",
    "                index, state = sess.run([sample, out_state], feed)\n",
    "                sentence += vocab_decode(index, vocab)\n",
    "            print(sentence + '\\n')\n",
    "           \n",
    "            #####\n",
    "            start = time.time()\n",
    "            saver.save(sess, 'checkpoints/arvix/char-rnn', iteration)\n",
    "        iteration += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
